from flask import Flask, render_template, request
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
app = Flask(__name__)
import joblib
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    text = request.form['fname']

    emp=np.zeros((1,359))
    feature_list=['able_text',
 'actually_text',
 'advice_text',
 'afraid_text',
 'ago_text',
 'angry_text',
 'anxiety_text',
 'anxious_text',
 'anymore_text',
 'asked_text',
 'attack_text',
 'attacks_text',
 'away_text',
 'bad_text',
 'bed_text',
 'believe_text',
 'best_text',
 'better_text',
 'big_text',
 'bit_text',
 'body_text',
 'boyfriend_text',
 'brain_text',
 'break_text',
 'came_text',
 'care_text',
 'changed_text',
 'childhood_text',
 'close_text',
 'come_text',
 'completely_text',
 'constantly_text',
 'control_text',
 'day_text',
 'days_text',
 'deal_text',
 'death_text',
 'depressed_text',
 'depression_text',
 'did_text',
 'didn_text',
 'didnt_text',
 'die_text',
 'difficult_text',
 'does_text',
 'doesn_text',
 'doesnt_text',
 'doing_text',
 'don_text',
 'don know_text',
 'don want_text',
 'dont_text',
 'dont know_text',
 'dont want_text',
 'edit_text',
 'emotions_text',
 'end_text',
 'experience_text',
 'experienced_text',
 'experiences_text',
 'face_text',
 'fact_text',
 'family_text',
 'far_text',
 'fear_text',
 'feel_text',
 'feel like_text',
 'feeling_text',
 'feels_text',
 'feels like_text',
 'felt_text',
 'felt like_text',
 'fine_text',
 'friend_text',
 'friends_text',
 'fuck_text',
 'fucking_text',
 'gets_text',
 'getting_text',
 'goes_text',
 'going_text',
 'gone_text',
 'gonna_text',
 'good_text',
 'got_text',
 'guess_text',
 'happen_text',
 'happened_text',
 'happy_text',
 'hard_text',
 'hate_text',
 'having_text',
 'head_text',
 'health_text',
 'hear_text',
 'heart_text',
 'help_text',
 'high_text',
 'home_text',
 'honestly_text',
 'hope_text',
 'horrible_text',
 'hours_text',
 'idk_text',
 'ill_text',
 'impossible_text',
 'issues_text',
 'ive_text',
 'job_text',
 'just_text',
 'just want_text',
 'kill_text',
 'kind_text',
 'know_text',
 'knows_text',
 'later_text',
 'leave_text',
 'left_text',
 'let_text',
 'life_text',
 'life just_text',
 'like_text',
 'like just_text',
 'literally_text',
 'little_text',
 'live_text',
 'lives_text',
 'living_text',
 'long_text',
 'look_text',
 'looking_text',
 'lose_text',
 'lost_text',
 'lot_text',
 'love_text',
 'loved_text',
 'make_text',
 'makes_text',
 'makes feel_text',
 'making_text',
 'man_text',
 'matter_text',
 'maybe_text',
 'meds_text',
 'mental_text',
 'mind_text',
 'mom_text',
 'month_text',
 'months_text',
 'morning_text',
 'need_text',
 'new_text',
 'night_text',
 'normal_text',
 'noticed_text',
 'numb_text',
 'okay_text',
 'old_text',
 'open_text',
 'outside_text',
 'pain_text',
 'panic_text',
 'panic attacks_text',
 'parents_text',
 'past_text',
 'people_text',
 'person_text',
 'physical_text',
 'place_text',
 'point_text',
 'post_text',
 'pretty_text',
 'problem_text',
 'ptsd_text',
 'real_text',
 'really_text',
 'reason_text',
 'recently_text',
 'relate_text',
 'relationship_text',
 'remember_text',
 'right_text',
 'room_text',
 'sad_text',
 'safe_text',
 'said_text',
 'say_text',
 'saying_text',
 'says_text',
 'scared_text',
 'schizophrenia_text',
 'school_text',
 'second_text',
 'seen_text',
 'self_text',
 'sense_text',
 'shit_text',
 'sick_text',
 'similar_text',
 'single_text',
 'sleep_text',
 'social_text',
 'sorry_text',
 'start_text',
 'started_text',
 'stop_text',
 'stuff_text',
 'support_text',
 'sure_text',
 'symptoms_text',
 'taking_text',
 'talk_text',
 'talking_text',
 'tell_text',
 'thank_text',
 'thanks_text',
 'thats_text',
 'therapist_text',
 'therapy_text',
 'theres_text',
 'thing_text',
 'things_text',
 'think_text',
 'thinking_text',
 'thought_text',
 'thoughts_text',
 'time_text',
 'times_text',
 'tired_text',
 'title_text',
 'today_text',
 'told_text',
 'took_text',
 'trauma_text',
 'tried_text',
 'truly_text',
 'try_text',
 'trying_text',
 'understand_text',
 'use_text',
 'used_text',
 'usually_text',
 'voices_text',
 'waking_text',
 'walk_text',
 'wanna_text',
 'want_text',
 'wanted_text',
 'way_text',
 'week_text',
 'weeks_text',
 'went_text',
 'wish_text',
 'wondering_text',
 'wont_text',
 'work_text',
 'worked_text',
 'working_text',
 'world_text',
 'worse_text',
 'wrong_text',
 'year_text',
 'years_text',
 'years ago_text',
 'yes_text',
 'yesterday_text',
 'abuse_text',
 'actually_text',
 'alive_text',
 'anxiety_text',
 'anxious_text',
 'anybody_text',
 'away_text',
 'bad_text',
 'bed_text',
 'better_text',
 'day_text',
 'deal_text',
 'death_text',
 'depression_text',
 'diagnosed_text',
 'did_text',
 'die_text',
 'does_text',
 'don_text',
 'dont_text',
 'episode_text',
 'everyday_text',
 'experience_text',
 'feel_text',
 'feel like_text',
 'feeling_text',
 'friend_text',
 'fuck_text',
 'fucking_text',
 'gets_text',
 'getting_text',
 'going_text',
 'good_text',
 'got_text',
 'happy_text',
 'hate_text',
 'having_text',
 'help_text',
 'hospital_text',
 'hour_text',
 'ive_text',
 'just_text',
 'kill_text',
 'know_text',
 'life_text',
 'like_text',
 'live_text',
 'living_text',
 'looking_text',
 'lost_text',
 'love_text',
 'make_text',
 'makes_text',
 'meds_text',
 'memory_text',
 'mom_text',
 'need_text',
 'night_text',
 'nightmares_text',
 'old_text',
 'parents_text',
 'past_text',
 'people_text',
 'person_text',
 'ptsd_text',
 'read_text',
 'really_text',
 'ruining_text',
 'sad_text',
 'say_text',
 'schizophrenia_text',
 'sex_text',
 'sleep_text',
 'stay_text',
 'suffering_text',
 'suicidal_text',
 'symptoms_text',
 'therapist_text',
 'therapy_text',
 'things_text',
 'think_text',
 'time_text',
 'times_text',
 'tired_text',
 'today_text',
 'told_text',
 'trauma_text',
 'triggered_text',
 'want_text',
 'wish_text',
 'worse_text',
 'worst_text',
 'years_text']
    empd=pd.DataFrame(emp,columns=feature_list)
    regex1=r'\b[a-zA-Z]{3,50}\b'
    cv_textt = CountVectorizer(analyzer='word',stop_words='english', strip_accents = 'ascii', ngram_range=(1, 6), min_df=.02,token_pattern=regex1)
    text=[text]
    New_text = cv_textt.fit_transform(text)
    New_text_df = pd.DataFrame(New_text.todense(), columns=[x+'_text' for x in cv_textt.get_feature_names_out()])
    common_cols = New_text_df.columns.intersection(feature_list)
    
    for i in range(0,len(common_cols)):

        empd[common_cols[i]]=1
    loaded_model =joblib.load('lr_model.sav')
    predictions = loaded_model.predict(empd)
    if len(common_cols)<3:
        t="Normal"
    else:
        if predictions==0:
            t="Signs of Depression"
        if predictions==1:
             t="Signs of Anxiety" 
        if predictions==2:
             t="Signs of PTSD"
        if predictions==3:
             t="Signs of Scizophrenia" 
    return render_template('index.html',p=t)


if __name__ == '__main__':
    app.run()